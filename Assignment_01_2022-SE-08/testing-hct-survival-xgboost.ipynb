{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":70942,"databundleVersionId":10381525,"sourceType":"competition"},{"sourceId":224054549,"sourceType":"kernelVersion"}],"dockerImageVersionId":30918,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-02-28T13:05:08.104357Z","iopub.execute_input":"2025-02-28T13:05:08.104808Z","iopub.status.idle":"2025-02-28T13:05:08.115646Z","shell.execute_reply.started":"2025-02-28T13:05:08.104775Z","shell.execute_reply":"2025-02-28T13:05:08.114414Z"}},"outputs":[{"name":"stdout","text":"/kaggle/input/training-hct-survival/training_columns.pkl\n/kaggle/input/training-hct-survival/cat_imputer.pkl\n/kaggle/input/training-hct-survival/num_imputer.pkl\n/kaggle/input/training-hct-survival/__results__.html\n/kaggle/input/training-hct-survival/encoder.pkl\n/kaggle/input/training-hct-survival/num_cols.pkl\n/kaggle/input/training-hct-survival/scaler.pkl\n/kaggle/input/training-hct-survival/cat_cols.pkl\n/kaggle/input/training-hct-survival/__notebook__.ipynb\n/kaggle/input/training-hct-survival/__output__.json\n/kaggle/input/training-hct-survival/xgboost_model.model\n/kaggle/input/training-hct-survival/custom.css\n/kaggle/input/equity-post-HCT-survival-predictions/sample_submission.csv\n/kaggle/input/equity-post-HCT-survival-predictions/data_dictionary.csv\n/kaggle/input/equity-post-HCT-survival-predictions/train.csv\n/kaggle/input/equity-post-HCT-survival-predictions/test.csv\n","output_type":"stream"}],"execution_count":7},{"cell_type":"code","source":"# Testing Notebook for XGBoost\n\nimport pandas as pd\nimport numpy as np\nfrom sklearn.preprocessing import OneHotEncoder, StandardScaler\nfrom sklearn.impute import SimpleImputer\nimport xgboost as xgb\nimport joblib\n\n# Define selected columns (same as training)\nselected_columns = [\n    \"prim_disease_hct\", \"hla_match_b_low\", \"prod_type\", \"year_hct\", \"obesity\", \n    \"donor_age\", \"prior_tumor\", \"gvhd_proph\", \"sex_match\", \"comorbidity_score\", \n    \"karnofsky_score\", \"donor_related\", \"age_at_hct\"\n]\n\n# Load test dataset\ntest_file_path = \"/kaggle/input/equity-post-HCT-survival-predictions/test.csv\"\ndf_test = pd.read_csv(test_file_path)\n\n# Keep only selected columns\ndf_test = df_test[selected_columns]\n\n# Load preprocessors\nnum_imputer = joblib.load(\"/kaggle/input/training-hct-survival/num_imputer.pkl\")\ncat_imputer = joblib.load(\"/kaggle/input/training-hct-survival/cat_imputer.pkl\")\nencoder = joblib.load(\"/kaggle/input/training-hct-survival/encoder.pkl\")\nscaler = joblib.load(\"/kaggle/input/training-hct-survival/scaler.pkl\")\n\n# Load numerical and categorical columns\nnum_cols = joblib.load(\"/kaggle/input/training-hct-survival/num_cols.pkl\")\ncat_cols = joblib.load(\"/kaggle/input/training-hct-survival/cat_cols.pkl\")\nprint(\"Numerical and categorical columns loaded!\")\n\n# Load the list of columns used in the training dataset\ntraining_columns = joblib.load(\"/kaggle/input/training-hct-survival/training_columns.pkl\")\n\n# Ensure all categorical columns exist before transformation\nfor col in cat_cols:\n    if col not in df_test.columns:\n        df_test[col] = np.nan  # Fill missing categorical columns\n\n# Handle missing values for categorical columns\ndf_test[cat_cols] = cat_imputer.transform(df_test[cat_cols])\n\n# Encode categorical features\nencoded_cats_test = encoder.transform(df_test[cat_cols])\ndf_test_encoded = pd.DataFrame(encoded_cats_test, columns=encoder.get_feature_names_out(cat_cols))\n\n# Drop original categorical columns and merge encoded ones\ndf_test = df_test.drop(columns=cat_cols, errors='ignore')  # Avoid KeyError\ndf_test = pd.concat([df_test, df_test_encoded], axis=1)\n\n# Standardize numerical features\ndf_test[num_cols] = scaler.transform(df_test[num_cols])\n\n# Convert to DMatrix\ndtest = xgb.DMatrix(df_test)\n\n# Load the trained model\nbst = xgb.Booster()\nbst.load_model(\"/kaggle/input/training-hct-survival/xgboost_model.model\")\n\n# Make predictions\npredictions = bst.predict(dtest)\n\n# Save predictions to a CSV file\nsubmission = pd.DataFrame({\n    \"ID\": df_test.index,\n    \"prediction\": predictions\n})\nsubmission.to_csv(\"submission.csv\", index=False)\nprint(\"XGBoost predictions saved!\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-28T13:05:10.373280Z","iopub.execute_input":"2025-02-28T13:05:10.373757Z","iopub.status.idle":"2025-02-28T13:05:10.428267Z","shell.execute_reply.started":"2025-02-28T13:05:10.373693Z","shell.execute_reply":"2025-02-28T13:05:10.427405Z"}},"outputs":[{"name":"stdout","text":"Numerical and categorical columns loaded!\nXGBoost predictions saved!\n","output_type":"stream"}],"execution_count":8},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}